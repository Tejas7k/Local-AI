# Local AI ğŸ¤–

Local AI is a privacy-focused web application that enables you to interact with Large Language Models (LLMs) while keeping your data secure. Unlike cloud-based AI services, Local AI processes all queries locally, ensuring complete confidentiality.

## âœ¨ Features  

- **Privacy-Focused** â€“ Runs entirely on your local machine, keeping your data confidential.  
- **User-Friendly Interface** â€“ A sleek and intuitive web UI for seamless interaction with LLMs.  
- **Code Block Highlighting** â€“ Displays code snippets with proper formatting for better readability.  
- **One-Click Copy** â€“ Easily copy the entire response or individual code snippets.  
- **Conversation History** â€“ Retains previous interactions locally for easy reference.  
- **Loading Indicator** â€“ Provides visual feedback during API requests.  

## ğŸ¥ Demo  

Check out the demo video showcasing Local AI in action:  

<video width="600" controls>
  <source src="sample/DEMO.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>

## ğŸ”§ Prerequisites  

Before running the application, ensure you have the following:  

- **Python 3.x** installed  
- **Flask**, **Requests**, and **Tenacity** libraries  
- **LLM API Key** (set as an environment variable `LLM_API_KEY`)  

## ğŸš€ Installation  

Follow these steps to set up and run Local AI:  

### 1ï¸âƒ£ Clone the Repository  

```bash
git clone https://github.com/Tejas7k/LocalAI.git
cd LocalAI
```

### 2ï¸âƒ£ Create a Virtual Environment (Recommended)  

```bash
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
venv\Scripts\activate     # Windows
```

### 3ï¸âƒ£ Install Dependencies  

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Set Up API Key  

Set your LLM API Key as an environment variable:  

```bash
export LLM_API_KEY="YOUR_API_KEY"  # macOS/Linux
set LLM_API_KEY="YOUR_API_KEY"     # Windows
```

For PowerShell:  
```powershell
$env:LLM_API_KEY = "YOUR_API_KEY"
```

### 5ï¸âƒ£ Run the Application  

```bash
python app.py
```

### 6ï¸âƒ£ Access the Web Interface  

Open your browser and navigate to:  

```
http://127.0.0.1:5000/
```

## ğŸ¯ Usage  

### ğŸ”¹ Enter Your Query  
![Input Field](sample/Query.png)  
Type your query in the input field.  

### ğŸ”¹ Click "Generate"  
![Generate Button](sample/Generate.png)  
Click the "Generate" button to process your request.  

### ğŸ”¹ View the Response  
![Response Area](sample/Response_View.png)  
Generated content will be displayed in the response area.  

### ğŸ”¹ Copy the Response  
![Copy Response Button](sample/Copy_whole.png)  
Click the **Copy Response** button to copy the full output.  

### ğŸ”¹ Copy Code Blocks  
![Copy Code Block](sample/copy_code_block.png)  
Copy individual code snippets with the **Copy** button.  

## ğŸ¤ Contributing  

Contributions are welcome! Feel free to submit pull requests or report issues.  

## ğŸ“œ License  

This project is licensed under the MIT License. See the [LICENSE](License)

## ğŸ™Œ Acknowledgments  

This project was made possible with the help of the following technologies:  

- [Python](https://www.python.org/) â€“ The core programming language used in this project.  
- [Flask](https://flask.palletsprojects.com/) â€“ A lightweight WSGI web framework for Python.  
- [Requests](https://docs.python-requests.org/en/latest/) â€“ For handling API requests.  
- [Tenacity](https://tenacity.readthedocs.io/en/latest/) â€“ For handling retries and failures.  
- [LLM API](https://platform.openai.com/docs/) â€“ Used for generating AI-powered responses.  
- [LLM Privacy](https://www.llmprivacy.com/) â€“ Ensuring data security and privacy for AI interactions.  


ğŸš€ _Developed with â¤ï¸ for privacy-conscious AI users._
