# Local AI ğŸš€  

Local AI is a privacy-focused web application that enables you to interact with Large Language Models (LLMs) while keeping your data secure. Unlike cloud-based AI services, Local AI processes all queries locally, ensuring complete confidentiality.

## âœ¨ Features  

- **Privacy-Focused** â€“ Runs entirely on your local machine, keeping your data confidential.  
- **User-Friendly Interface** â€“ A sleek and intuitive web UI for seamless interaction with LLMs.  
- **Code Block Highlighting** â€“ Displays code snippets with proper formatting for better readability.  
- **One-Click Copy** â€“ Easily copy the entire response or individual code snippets.  
- **Conversation History** â€“ Retains previous interactions locally for easy reference.  
- **Loading Indicator** â€“ Provides visual feedback during API requests.  

## ğŸ¥ Demo  

Check out the demo video showcasing Local AI in action:  

[![Demo](sample/DEMO.mp4)](sample/DEMO.mp4)  

## ğŸ”§ Prerequisites  

Before running the application, ensure you have the following:  

- **Python 3.x** installed  
- **Flask**, **Requests**, and **Tenacity** libraries  
- **LLM API Key** (set as an environment variable `LLM_API_KEY`)  

## ğŸš€ Installation  

Follow these steps to set up and run Local AI:  

### 1ï¸âƒ£ Clone the Repository  

```bash
git clone https://github.com/your-username/LocalAI.git
cd LocalAI
```

### 2ï¸âƒ£ Create a Virtual Environment (Recommended)  

```bash
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
venv\Scripts\activate     # Windows
```

### 3ï¸âƒ£ Install Dependencies  

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Set Up API Key  

Set your LLM API Key as an environment variable:  

```bash
export LLM_API_KEY="YOUR_API_KEY"  # macOS/Linux
set LLM_API_KEY="YOUR_API_KEY"     # Windows
```

For PowerShell:  
```powershell
$env:LLM_API_KEY = "YOUR_API_KEY"
```

### 5ï¸âƒ£ Run the Application  

```bash
python app.py
```

### 6ï¸âƒ£ Access the Web Interface  

Open your browser and navigate to:  

```
http://127.0.0.1:5000/
```

## ğŸ¯ Usage  

### ğŸ”¹ Enter Your Query  
![Input Field](sample/Query.png)  
Type your query in the input field.  

### ğŸ”¹ Click "Generate"  
![Generate Button](sample/Generate.png)  
Click the "Generate" button to process your request.  

### ğŸ”¹ View the Response  
![Response Area](sample/Response_View.png)  
Generated content will be displayed in the response area.  

### ğŸ”¹ Copy the Response  
![Copy Response Button](sample/Copy_whole.png)  
Click the **Copy Response** button to copy the full output.  

### ğŸ”¹ Copy Code Blocks  
![Copy Code Block](sample/copy_code_block.png)  
Copy individual code snippets with the **Copy** button.  

## ğŸ¤ Contributing  

Contributions are welcome! Feel free to submit pull requests or report issues.  

## ğŸ“œ License  

This project is licensed under the MIT License. See the [LICENSE](License)

## ğŸ™Œ Acknowledgments  

Special thanks to:  
- **LLM Models** for AI capabilities  
- **Flask** for backend framework  
- **marked.js & Prism.js** (if used) for UI enhancements  

---
ğŸš€ _Developed with â¤ï¸ for privacy-conscious AI users._
```

Now you can copy the whole thing easily! Let me know if you need any modifications. ğŸš€
